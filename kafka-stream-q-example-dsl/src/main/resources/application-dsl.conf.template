akka {
  loglevel = INFO
  log-config-on-start = on
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
}

kafka {
  # true if use local kafka server
  # false otherwise
  # if true, then setting of brokers below is ignored and set to that of KafkaLocalServer
  localserver = true

  ## bootstrap servers for Kafka
  brokers = "localhost:9092"
  brokers = ${?KAFKA_BROKERS}

  ## consumer group
  group = "group-dsl"
  group = ${?KAFKA_GROUP_DSL}

  ## the source topic - processing starts with
  ## data in this topic (to be loaded by ingestion)
  fromtopic = "server-log-dsl"
  fromtopic = ${?KAFKA_FROM_TOPIC_DSL}

  ## processed records goes here in json of LogRecord
  totopic = "processed-log"
  totopic = ${?KAFKA_TO_TOPIC_DSL}

  ## this gets the avro serialized data from totopic for processing by Kafka Connect
  ## HDFS sink connector
  avrotopic = "avro-topic"
  avrotopic = ${?KAFKA_AVRO_TOPIC_DSL}

  ## summary access information gets pushed here
  summaryaccesstopic = "summary-access-log"
  summaryaccesstopic = ${?KAFKA_SUMMARY_ACCESS_TOPIC_DSL}

  ## windowed summary access information gets pushed here
  windowedsummaryaccesstopic = "windowed-summary-access-log"
  windowedsummaryaccesstopic = ${?KAFKA_WINDOWED_SUMMARY_ACCESS_TOPIC_DSL}

  ## summary payload information gets pushed here
  summarypayloadtopic = "summary-payload-log"
  summarypayloadtopic = ${?KAFKA_SUMMARY_PAYLOAD_TOPIC_DSL}

  ## windowed summary payload information gets pushed here
  windowedsummarypayloadtopic = "windowed-summary-payload-log"
  windowedsummarypayloadtopic = ${?KAFKA_WINDOWED_SUMMARY_PAYLOAD_TOPIC_DSL}

  ## error topic for the initial processing
  errortopic = "logerr-dsl"
  errortopic = ${?KAFKA_ERROR_TOPIC_DSL}

  # schemaregistryurl = "http://localhost:8081"
  # schemaregistryurl = ${?SCHEMA_REGISTRY_URL}

  ## folder where state stores are created by Kafka Streams
  statestoredir = "/tmp/kafka-streams"
  statestoredir = ${?STATESTOREDIR}

  ## settings for data ingestion
  loader {
    sourcetopic = ${kafka.fromtopic}
    sourcetopic = ${?KAFKA_FROM_TOPIC_DSL}

    directorytowatch = "/Users/myhome/ClarkNet-HTTP"
    directorytowatch = ${?DIRECTORY_TO_WATCH}

    pollinterval = 1 second
  }
}

# http endpoints of the weblog microservice
http {
  # The port the dashboard listens on
  port = 7070
  port = ${?PORT0}

  # The interface the dashboard listens on
  interface = "localhost"
  interface = ${?INTERFACE_DSL}
}

